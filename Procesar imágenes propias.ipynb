{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcular dimensiones necesarias\n",
    "Nuestro dataset proviene de dos fuentes: fotos propias y el dataset DETRAC.\n",
    "Las primeras tiene un tamaño de 4608x2592, por lo tanto una relación de 4/3, mientras que DETRAC mide 960x540(16/9).\n",
    "\n",
    "A la hora del entrenamiento todas las imágenes de entrada deben tener el mismo tamaño, así que vamos a reducir nuestras fotos al tamaño que utiliza DETRAC.\n",
    "\n",
    "Primero empezamos calculando la nueva altura necesaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DETRAC 960x540 = 1.7777777777777777\n",
      "Alba 4608x3456 = 1.3333333333333333\n",
      "Si recortamos la altura: Alba 4608x2592.0 = 1.7777777777777777\n"
     ]
    }
   ],
   "source": [
    "DETRAC_width = 960\n",
    "DETRAC_height = 540\n",
    "DETRAC_relacion = DETRAC_width/DETRAC_height\n",
    "print(\"DETRAC {}x{} = {}\".format(DETRAC_width,DETRAC_height,DETRAC_relacion))\n",
    "\n",
    "Alba_width = 4608\n",
    "Alba_height = 3456\n",
    "Alba_relacion = Alba_width/Alba_height\n",
    "print(\"Alba {}x{} = {}\".format(Alba_width,Alba_height,Alba_relacion))\n",
    "\n",
    "Alba_width = 4608\n",
    "Alba_height = Alba_width*DETRAC_height/DETRAC_width\n",
    "Alba_relacion = Alba_width/Alba_height\n",
    "print(\"Si recortamos la altura: Alba {}x{} = {}\".format(Alba_width,Alba_height,Alba_relacion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasar fotos a resolución 4608x2592\n",
    "Resulta que la altura necesario para tener una resolución de 16/9 es de 2592 pixeles.\n",
    "\n",
    "A continuación recortamos las fotos para que tengan dicho tamaño.\n",
    "\n",
    "Utilizando la primera casilla podremos procesar las fotos donde los coches se vean cortados al cortarlos desde arriba de todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recortar una foto\n",
    "img_path = \"Fotos Alba/DSCF1466.JPG\"\n",
    "img_name = img_path.split(\"/\")[-1]\n",
    "im = Image.open(img_path)\n",
    "\n",
    "recortada = im.crop((0, 850, 4608, 3442))\n",
    "recortada.save(\"Fotos Alba recortadas/\" + img_name[:-4] + \".jpg\")\n",
    "\n",
    "#Imagenes no recortadas desde (0,0)\n",
    "#DSCF1445\n",
    "#DSCF1455\n",
    "#DSCF1461\n",
    "#DSCF1463\n",
    "#DSCF1466"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recortar toda la carpeta\n",
    "for img_path in glob.glob(\"Fotos Alba/*.JPG\"):\n",
    "    print(img_path)\n",
    "    img_name = img_path.split(\"/\")[-1]\n",
    "    im = Image.open(img_path)\n",
    "\n",
    "    recortada = im.crop((0, 0, 4608, 2592))\n",
    "    recortada.save(\"Fotos Alba recortadas/\" + img_name[:-4] + \".jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasar anotaciones de 4608 × 2598 a 960×540\n",
    "\n",
    "A continuación reducimos la resolución de las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Recortar toda la carpeta\n",
    "for img_path in glob.glob(\"Fotos Alba recortadas/*.jpg\"):\n",
    "    print(img_path)\n",
    "    img_name = img_path.split(\"/\")[-1]\n",
    "    im = Image.open(img_path)\n",
    "\n",
    "    size = 960, 540\n",
    "    recortada = im.resize(size, Image.ANTIALIAS)\n",
    "    recortada.save(\"Fotos Alba resolucion OK/\" + img_name[:-4] + \".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pasar anotaciones a nueva resolución\n",
    "Por último, como las imágenes ya estaban anotadas debemos de pasar las anotaciones a las nuevas medidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Procesar una imagen\n",
    "# Leer archivo de anotaciones\n",
    "data = json.load(open('Fotos Alba/via_region_data (1).json'))\n",
    "init_width = 4608\n",
    "init_height = 3456\n",
    "final_width = 960\n",
    "final_height = 720\n",
    "\n",
    "# Calculo la clave\n",
    "image_name = 'DSCF1440.JPG'\n",
    "image_path = 'Fotos Alba/' + image_name\n",
    "image_size = os.stat(image_path).st_size # Tamanho\n",
    "image_name = os.path.basename(image_path)    # Nombre\n",
    "vgg_key = \"{}{}\".format(image_name, image_size)\n",
    "datos_leidos = data[vgg_key]\n",
    "print(data[vgg_key])\n",
    "\n",
    "# Añado al json\n",
    "new_image_path = 'Fotos Alba resolucion OK/' + image_name\n",
    "new_image_size = os.stat(new_image_path).st_size # Tamanho\n",
    "new_image_name = os.path.basename(new_image_path)[:-4] + \".jpg\"    # Nombre\n",
    "data[vgg_key]['size'] = new_image_size\n",
    "data[vgg_key]['filename'] = new_image_name\n",
    "print(data[vgg_key])\n",
    "\n",
    "anotaciones = data[vgg_key]['regions']\n",
    "for anotacion in anotaciones:\n",
    "    print(anotaciones[anotacion]['shape_attributes'])\n",
    "    new_x = final_width * anotaciones[anotacion]['shape_attributes']['x'] / init_width\n",
    "    new_y = final_height * anotaciones[anotacion]['shape_attributes']['y'] / init_height\n",
    "    new_width = final_width * anotaciones[anotacion]['shape_attributes']['width'] / init_width\n",
    "    new_height = final_height* anotaciones[anotacion]['shape_attributes']['height'] / init_height\n",
    "    \n",
    "    anotaciones[anotacion]['shape_attributes']['x'] = new_x\n",
    "    anotaciones[anotacion]['shape_attributes']['y'] = new_y\n",
    "    anotaciones[anotacion]['shape_attributes']['width'] = new_width\n",
    "    anotaciones[anotacion]['shape_attributes']['height'] = new_height\n",
    "    \n",
    "print(data[vgg_key])\n",
    "\n",
    "new_key = new_image_name + str(new_image_size)\n",
    "vgg_main = {new_key : data[vgg_key]}\n",
    "\n",
    "with open(\"prueba.json\", \"w\") as f:\n",
    "            json.dump(vgg_main, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Procesar una carpeta\n",
    "\n",
    "# Leer archivo de anotaciones\n",
    "data = json.load(open('Fotos Alba/via_region_data (1).json'))\n",
    "init_width = 4608\n",
    "init_height = 3456\n",
    "final_width = 960\n",
    "final_height = 720\n",
    "vgg_main = OrderedDict()\n",
    "\n",
    "for image_path in glob.glob(\"Fotos Alba/*.JPG\"):\n",
    "\n",
    "    # Calculo la clave\n",
    "    print(image_path)\n",
    "    image_name = image_path.split(\"/\")[-1]\n",
    "    image_size = os.stat(image_path).st_size # Tamanho\n",
    "    image_name = os.path.basename(image_path)    # Nombre\n",
    "    vgg_key = \"{}{}\".format(image_name, image_size)\n",
    "    datos_leidos = data[vgg_key]\n",
    "    #print(data[vgg_key])\n",
    "\n",
    "    # Añado al json\n",
    "    new_image_path = 'Fotos Alba resolucion OK/' + image_name\n",
    "    new_image_size = os.stat(new_image_path).st_size # Tamanho\n",
    "    new_image_name = os.path.basename(new_image_path)[:-4] + \".jpg\"    # Nombre\n",
    "    data[vgg_key]['size'] = new_image_size\n",
    "    data[vgg_key]['filename'] = new_image_name\n",
    "    #print(data[vgg_key])\n",
    "\n",
    "    anotaciones = data[vgg_key]['regions']\n",
    "    for anotacion in anotaciones:\n",
    "        #print(anotaciones[anotacion]['shape_attributes'])\n",
    "        new_x = final_width * anotaciones[anotacion]['shape_attributes']['x'] / init_width\n",
    "        new_y = final_height * anotaciones[anotacion]['shape_attributes']['y'] / init_height\n",
    "        new_width = final_width * anotaciones[anotacion]['shape_attributes']['width'] / init_width\n",
    "        new_height = final_height* anotaciones[anotacion]['shape_attributes']['height'] / init_height\n",
    "\n",
    "        anotaciones[anotacion]['shape_attributes']['x'] = new_x\n",
    "        anotaciones[anotacion]['shape_attributes']['y'] = new_y\n",
    "        anotaciones[anotacion]['shape_attributes']['width'] = new_width\n",
    "        anotaciones[anotacion]['shape_attributes']['height'] = new_height\n",
    "        anotaciones[anotacion]['shape_attributes']['height'] = new_height\n",
    "        anotaciones[anotacion][\"region_attributes\"][\"Class\"] = \"car\"\n",
    "\n",
    "    #print(data[vgg_key])\n",
    "\n",
    "    new_key = new_image_name + str(new_image_size)\n",
    "    vgg_main.update({new_key : data[vgg_key]})\n",
    "\n",
    "with open(\"prueba.json\", \"w\") as f:\n",
    "    json.dump(vgg_main, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
